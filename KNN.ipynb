{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the data nba_logreg.csv . Each row represents an NBA player with their stats such as PTS (points per game),  BLK (blocks), STL (steals) etc. The last column shows whether the player's career length is more than 5 years (1) or not (0). Your task is to build a knn model that predicts whether a player's career length is more than 5 years or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell first\n",
    "from datascience import * \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "import numpy as np\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load the data. We want to use the first 80% of the data for training and the last 20% for testing. Split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Name</th> <th>GP</th> <th>MIN</th> <th>PTS</th> <th>FGM</th> <th>FGA</th> <th>FG%</th> <th>3P Made</th> <th>3PA</th> <th>3P%</th> <th>FTM</th> <th>FTA</th> <th>FT%</th> <th>OREB</th> <th>DREB</th> <th>REB</th> <th>AST</th> <th>STL</th> <th>BLK</th> <th>TOV</th> <th>TARGET_5Yrs</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Brandon Ingram </td> <td>36  </td> <td>27.4</td> <td>7.4 </td> <td>2.6 </td> <td>7.6 </td> <td>34.7</td> <td>0.5    </td> <td>2.1 </td> <td>25  </td> <td>1.6 </td> <td>2.3 </td> <td>69.9</td> <td>0.7 </td> <td>3.4 </td> <td>4.1 </td> <td>1.9 </td> <td>0.4 </td> <td>0.4 </td> <td>1.3 </td> <td>0          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Andrew Harrison</td> <td>35  </td> <td>26.9</td> <td>7.2 </td> <td>2   </td> <td>6.7 </td> <td>29.6</td> <td>0.7    </td> <td>2.8 </td> <td>23.5</td> <td>2.6 </td> <td>3.4 </td> <td>76.5</td> <td>0.5 </td> <td>2   </td> <td>2.4 </td> <td>3.7 </td> <td>1.1 </td> <td>0.5 </td> <td>1.6 </td> <td>0          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>JaKarr Sampson </td> <td>74  </td> <td>15.3</td> <td>5.2 </td> <td>2   </td> <td>4.7 </td> <td>42.2</td> <td>0.4    </td> <td>1.7 </td> <td>24.4</td> <td>0.9 </td> <td>1.3 </td> <td>67  </td> <td>0.5 </td> <td>1.7 </td> <td>2.2 </td> <td>1   </td> <td>0.5 </td> <td>0.3 </td> <td>1   </td> <td>0          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Malik Sealy    </td> <td>58  </td> <td>11.6</td> <td>5.7 </td> <td>2.3 </td> <td>5.5 </td> <td>42.6</td> <td>0.1    </td> <td>0.5 </td> <td>22.6</td> <td>0.9 </td> <td>1.3 </td> <td>68.9</td> <td>1   </td> <td>0.9 </td> <td>1.9 </td> <td>0.8 </td> <td>0.6 </td> <td>0.1 </td> <td>1   </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Matt Geiger    </td> <td>48  </td> <td>11.5</td> <td>4.5 </td> <td>1.6 </td> <td>3   </td> <td>52.4</td> <td>0      </td> <td>0.1 </td> <td>0   </td> <td>1.3 </td> <td>1.9 </td> <td>67.4</td> <td>1   </td> <td>1.5 </td> <td>2.5 </td> <td>0.3 </td> <td>0.3 </td> <td>0.4 </td> <td>0.8 </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Tony Bennett   </td> <td>75  </td> <td>11.4</td> <td>3.7 </td> <td>1.5 </td> <td>3.5 </td> <td>42.3</td> <td>0.3    </td> <td>1.1 </td> <td>32.5</td> <td>0.4 </td> <td>0.5 </td> <td>73.2</td> <td>0.2 </td> <td>0.7 </td> <td>0.8 </td> <td>1.8 </td> <td>0.4 </td> <td>0   </td> <td>0.7 </td> <td>0          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Don MacLean    </td> <td>62  </td> <td>10.9</td> <td>6.6 </td> <td>2.5 </td> <td>5.8 </td> <td>43.5</td> <td>0      </td> <td>0.1 </td> <td>50  </td> <td>1.5 </td> <td>1.8 </td> <td>81.1</td> <td>0.5 </td> <td>1.4 </td> <td>2   </td> <td>0.6 </td> <td>0.2 </td> <td>0.1 </td> <td>0.7 </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Tracy Murray   </td> <td>48  </td> <td>10.3</td> <td>5.7 </td> <td>2.3 </td> <td>5.4 </td> <td>41.5</td> <td>0.4    </td> <td>1.5 </td> <td>30  </td> <td>0.7 </td> <td>0.8 </td> <td>87.5</td> <td>0.8 </td> <td>0.9 </td> <td>1.7 </td> <td>0.2 </td> <td>0.2 </td> <td>0.1 </td> <td>0.7 </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Duane Cooper   </td> <td>65  </td> <td>9.9 </td> <td>2.4 </td> <td>1   </td> <td>2.4 </td> <td>39.2</td> <td>0.1    </td> <td>0.5 </td> <td>23.3</td> <td>0.4 </td> <td>0.5 </td> <td>71.4</td> <td>0.2 </td> <td>0.6 </td> <td>0.8 </td> <td>2.3 </td> <td>0.3 </td> <td>0   </td> <td>1.1 </td> <td>0          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Dave Johnson   </td> <td>42  </td> <td>8.5 </td> <td>3.7 </td> <td>1.4 </td> <td>3.5 </td> <td>38.3</td> <td>0.1    </td> <td>0.3 </td> <td>21.4</td> <td>1   </td> <td>1.4 </td> <td>67.8</td> <td>0.4 </td> <td>0.7 </td> <td>1.1 </td> <td>0.3 </td> <td>0.2 </td> <td>0   </td> <td>0.7 </td> <td>0          </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (1330 rows omitted)</p>"
      ],
      "text/plain": [
       "Name            | GP   | MIN  | PTS  | FGM  | FGA  | FG%  | 3P Made | 3PA  | 3P%  | FTM  | FTA  | FT%  | OREB | DREB | REB  | AST  | STL  | BLK  | TOV  | TARGET_5Yrs\n",
       "Brandon Ingram  | 36   | 27.4 | 7.4  | 2.6  | 7.6  | 34.7 | 0.5     | 2.1  | 25   | 1.6  | 2.3  | 69.9 | 0.7  | 3.4  | 4.1  | 1.9  | 0.4  | 0.4  | 1.3  | 0\n",
       "Andrew Harrison | 35   | 26.9 | 7.2  | 2    | 6.7  | 29.6 | 0.7     | 2.8  | 23.5 | 2.6  | 3.4  | 76.5 | 0.5  | 2    | 2.4  | 3.7  | 1.1  | 0.5  | 1.6  | 0\n",
       "JaKarr Sampson  | 74   | 15.3 | 5.2  | 2    | 4.7  | 42.2 | 0.4     | 1.7  | 24.4 | 0.9  | 1.3  | 67   | 0.5  | 1.7  | 2.2  | 1    | 0.5  | 0.3  | 1    | 0\n",
       "Malik Sealy     | 58   | 11.6 | 5.7  | 2.3  | 5.5  | 42.6 | 0.1     | 0.5  | 22.6 | 0.9  | 1.3  | 68.9 | 1    | 0.9  | 1.9  | 0.8  | 0.6  | 0.1  | 1    | 1\n",
       "Matt Geiger     | 48   | 11.5 | 4.5  | 1.6  | 3    | 52.4 | 0       | 0.1  | 0    | 1.3  | 1.9  | 67.4 | 1    | 1.5  | 2.5  | 0.3  | 0.3  | 0.4  | 0.8  | 1\n",
       "Tony Bennett    | 75   | 11.4 | 3.7  | 1.5  | 3.5  | 42.3 | 0.3     | 1.1  | 32.5 | 0.4  | 0.5  | 73.2 | 0.2  | 0.7  | 0.8  | 1.8  | 0.4  | 0    | 0.7  | 0\n",
       "Don MacLean     | 62   | 10.9 | 6.6  | 2.5  | 5.8  | 43.5 | 0       | 0.1  | 50   | 1.5  | 1.8  | 81.1 | 0.5  | 1.4  | 2    | 0.6  | 0.2  | 0.1  | 0.7  | 1\n",
       "Tracy Murray    | 48   | 10.3 | 5.7  | 2.3  | 5.4  | 41.5 | 0.4     | 1.5  | 30   | 0.7  | 0.8  | 87.5 | 0.8  | 0.9  | 1.7  | 0.2  | 0.2  | 0.1  | 0.7  | 1\n",
       "Duane Cooper    | 65   | 9.9  | 2.4  | 1    | 2.4  | 39.2 | 0.1     | 0.5  | 23.3 | 0.4  | 0.5  | 71.4 | 0.2  | 0.6  | 0.8  | 2.3  | 0.3  | 0    | 1.1  | 0\n",
       "Dave Johnson    | 42   | 8.5  | 3.7  | 1.4  | 3.5  | 38.3 | 0.1     | 0.3  | 21.4 | 1    | 1.4  | 67.8 | 0.4  | 0.7  | 1.1  | 0.3  | 0.2  | 0    | 0.7  | 0\n",
       "... (1330 rows omitted)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your answer here\n",
    "data = Table.read_table('nba_logreg.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 268)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows = data.num_rows\n",
    "training_size = int(total_rows*0.8)\n",
    "test_size = int(total_rows*0.2)\n",
    "data_shuffled =data.shuffle()\n",
    "training_size,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Name</th> <th>GP</th> <th>MIN</th> <th>PTS</th> <th>FGM</th> <th>FGA</th> <th>FG%</th> <th>3P Made</th> <th>3PA</th> <th>3P%</th> <th>FTM</th> <th>FTA</th> <th>FT%</th> <th>OREB</th> <th>DREB</th> <th>REB</th> <th>AST</th> <th>STL</th> <th>BLK</th> <th>TOV</th> <th>TARGET_5Yrs</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Adreian Payne  </td> <td>32  </td> <td>23.1</td> <td>6.7 </td> <td>2.8 </td> <td>6.9 </td> <td>41.4</td> <td>0      </td> <td>0.3 </td> <td>11.1</td> <td>0.9 </td> <td>1.4 </td> <td>65.2</td> <td>1.5 </td> <td>3.6 </td> <td>5.1 </td> <td>0.9 </td> <td>0.6 </td> <td>0.3 </td> <td>1.4 </td> <td>0          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Rasual Butler  </td> <td>72  </td> <td>21  </td> <td>7.5 </td> <td>2.9 </td> <td>7.9 </td> <td>36.2</td> <td>0.7    </td> <td>2.4 </td> <td>29.2</td> <td>1.1 </td> <td>1.4 </td> <td>73.1</td> <td>0.4 </td> <td>2.2 </td> <td>2.6 </td> <td>1.3 </td> <td>0.3 </td> <td>0.6 </td> <td>1.1 </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Adrian Griffin </td> <td>72  </td> <td>26.8</td> <td>6.7 </td> <td>2.4 </td> <td>5.7 </td> <td>42.4</td> <td>0.2    </td> <td>0.8 </td> <td>28.1</td> <td>1.7 </td> <td>2.2 </td> <td>75.3</td> <td>1.8 </td> <td>3.4 </td> <td>5.2 </td> <td>2.5 </td> <td>1.6 </td> <td>0.2 </td> <td>1.3 </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bob Thornton   </td> <td>71  </td> <td>18.6</td> <td>4.7 </td> <td>1.8 </td> <td>3.9 </td> <td>45.6</td> <td>0      </td> <td>0   </td> <td>0   </td> <td>1.2 </td> <td>2.3 </td> <td>53.1</td> <td>1.6 </td> <td>2.5 </td> <td>4.1 </td> <td>0.6 </td> <td>0.4 </td> <td>0.1 </td> <td>1.2 </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Howard Eisley  </td> <td>49  </td> <td>11.3</td> <td>2.4 </td> <td>0.8 </td> <td>2.5 </td> <td>32.8</td> <td>0.2    </td> <td>0.8 </td> <td>24.3</td> <td>0.6 </td> <td>0.8 </td> <td>77.5</td> <td>0.2 </td> <td>0.7 </td> <td>1   </td> <td>1.9 </td> <td>0.4 </td> <td>0.1 </td> <td>1   </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Tom Hammonds   </td> <td>61  </td> <td>13.2</td> <td>5.3 </td> <td>2.1 </td> <td>4.8 </td> <td>43.7</td> <td>0      </td> <td>0   </td> <td>0   </td> <td>1   </td> <td>1.6 </td> <td>64.3</td> <td>1   </td> <td>1.8 </td> <td>2.8 </td> <td>0.8 </td> <td>0.2 </td> <td>0.2 </td> <td>0.8 </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Earl Boykins   </td> <td>22  </td> <td>10  </td> <td>3   </td> <td>1.4 </td> <td>3.6 </td> <td>38  </td> <td>0.1    </td> <td>0.8 </td> <td>16.7</td> <td>0.1 </td> <td>0.1 </td> <td>66.7</td> <td>0.3 </td> <td>0.5 </td> <td>0.8 </td> <td>1.5 </td> <td>0.3 </td> <td>0   </td> <td>0.9 </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Greg Monroe    </td> <td>80  </td> <td>27.8</td> <td>9.4 </td> <td>3.8 </td> <td>6.9 </td> <td>55.1</td> <td>0      </td> <td>0   </td> <td>0   </td> <td>1.8 </td> <td>2.9 </td> <td>62.2</td> <td>3.1 </td> <td>4.4 </td> <td>7.5 </td> <td>1.3 </td> <td>1.2 </td> <td>0.6 </td> <td>1   </td> <td>1          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Derrick Brown  </td> <td>57  </td> <td>9.4 </td> <td>3.3 </td> <td>1.2 </td> <td>2.6 </td> <td>46.3</td> <td>0      </td> <td>0.1 </td> <td>28.6</td> <td>0.8 </td> <td>1.3 </td> <td>66.7</td> <td>0.5 </td> <td>0.8 </td> <td>1.4 </td> <td>0.3 </td> <td>0.4 </td> <td>0.2 </td> <td>0.3 </td> <td>0          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Walt Szczerbiak</td> <td>73  </td> <td>29.7</td> <td>11.6</td> <td>4.7 </td> <td>9.2 </td> <td>51.1</td> <td>0.4    </td> <td>1.1 </td> <td>35.9</td> <td>1.8 </td> <td>2.2 </td> <td>82.6</td> <td>1.2 </td> <td>2.5 </td> <td>3.7 </td> <td>2.8 </td> <td>0.8 </td> <td>0.3 </td> <td>1.1 </td> <td>0          </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (1062 rows omitted)</p>"
      ],
      "text/plain": [
       "Name            | GP   | MIN  | PTS  | FGM  | FGA  | FG%  | 3P Made | 3PA  | 3P%  | FTM  | FTA  | FT%  | OREB | DREB | REB  | AST  | STL  | BLK  | TOV  | TARGET_5Yrs\n",
       "Adreian Payne   | 32   | 23.1 | 6.7  | 2.8  | 6.9  | 41.4 | 0       | 0.3  | 11.1 | 0.9  | 1.4  | 65.2 | 1.5  | 3.6  | 5.1  | 0.9  | 0.6  | 0.3  | 1.4  | 0\n",
       "Rasual Butler   | 72   | 21   | 7.5  | 2.9  | 7.9  | 36.2 | 0.7     | 2.4  | 29.2 | 1.1  | 1.4  | 73.1 | 0.4  | 2.2  | 2.6  | 1.3  | 0.3  | 0.6  | 1.1  | 1\n",
       "Adrian Griffin  | 72   | 26.8 | 6.7  | 2.4  | 5.7  | 42.4 | 0.2     | 0.8  | 28.1 | 1.7  | 2.2  | 75.3 | 1.8  | 3.4  | 5.2  | 2.5  | 1.6  | 0.2  | 1.3  | 1\n",
       "Bob Thornton    | 71   | 18.6 | 4.7  | 1.8  | 3.9  | 45.6 | 0       | 0    | 0    | 1.2  | 2.3  | 53.1 | 1.6  | 2.5  | 4.1  | 0.6  | 0.4  | 0.1  | 1.2  | 1\n",
       "Howard Eisley   | 49   | 11.3 | 2.4  | 0.8  | 2.5  | 32.8 | 0.2     | 0.8  | 24.3 | 0.6  | 0.8  | 77.5 | 0.2  | 0.7  | 1    | 1.9  | 0.4  | 0.1  | 1    | 1\n",
       "Tom Hammonds    | 61   | 13.2 | 5.3  | 2.1  | 4.8  | 43.7 | 0       | 0    | 0    | 1    | 1.6  | 64.3 | 1    | 1.8  | 2.8  | 0.8  | 0.2  | 0.2  | 0.8  | 1\n",
       "Earl Boykins    | 22   | 10   | 3    | 1.4  | 3.6  | 38   | 0.1     | 0.8  | 16.7 | 0.1  | 0.1  | 66.7 | 0.3  | 0.5  | 0.8  | 1.5  | 0.3  | 0    | 0.9  | 1\n",
       "Greg Monroe     | 80   | 27.8 | 9.4  | 3.8  | 6.9  | 55.1 | 0       | 0    | 0    | 1.8  | 2.9  | 62.2 | 3.1  | 4.4  | 7.5  | 1.3  | 1.2  | 0.6  | 1    | 1\n",
       "Derrick Brown   | 57   | 9.4  | 3.3  | 1.2  | 2.6  | 46.3 | 0       | 0.1  | 28.6 | 0.8  | 1.3  | 66.7 | 0.5  | 0.8  | 1.4  | 0.3  | 0.4  | 0.2  | 0.3  | 0\n",
       "Walt Szczerbiak | 73   | 29.7 | 11.6 | 4.7  | 9.2  | 51.1 | 0.4     | 1.1  | 35.9 | 1.8  | 2.2  | 82.6 | 1.2  | 2.5  | 3.7  | 2.8  | 0.8  | 0.3  | 1.1  | 0\n",
       "... (1062 rows omitted)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data_shuffled.take(np.arange(0,training_size))\n",
    "test = data_shuffled.take(np.arange(training_size,training_size+test_size))\n",
    "train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Build a knn classifier which uses all numericals columns (except Target_5Yrs) as features to predict Target_5Yrs using the training data. Set the k parameter of knn to 3. Calculate your classifier's accuracy on your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write your answer here**\n",
    "\n",
    "\n",
    "train_with_numeric=train.drop('Name')\n",
    " \n",
    "def standard_units(x):\n",
    "    x =np.array(x)\n",
    "    return (x - np.mean(x))/np.std(x)\n",
    "\n",
    "def standartUnitConverter(table):\n",
    "    columnsize=table.num_columns\n",
    "   \n",
    "    table =Table()\n",
    "   \n",
    "    for i in range(0,columnsize):\n",
    "       \n",
    "        array=standard_units(table.column(0))\n",
    "        table = table.with_column(str(i)+'.column',array)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return table\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def distance(data1,data2):\n",
    "    \n",
    "    data1=np.array(data1)\n",
    "    data2=np.array(data2)\n",
    "\n",
    "    \n",
    "    return np.sqrt(np.sum((data1-data2)**2))\n",
    "    \n",
    "def distanceCalculator(train_with_numeric, new):\n",
    "    data_without_target =train_with_numeric.drop('TARGET_5Yrs')\n",
    "   \n",
    "    def subDistance(row):\n",
    "        return distance(np.array(new),np.array(row))\n",
    "    return data_without_target.apply(subDistance)\n",
    "\n",
    "def appending_sorted_DistancetoTable(data_without_target, new):\n",
    "    \n",
    "    return data_without_target.with_column('Distance',distanceCalculator(data_without_target, new)).sort('Distance')\n",
    "\n",
    "def closest(data,newpoint,k):\n",
    "    \n",
    "    data_with_distance = appending_sorted_DistancetoTable(data,newpoint)\n",
    "    taken_k=data_with_distance.take(np.arange(0,k))\n",
    "    return taken_k\n",
    "\n",
    "train_without_class=train_with_numeric.drop('TARGET_5Yrs')\n",
    "\n",
    "\n",
    "# there are different approach to assign class for new point one of the is majority\n",
    "\n",
    "\n",
    "def classDetection(train,new,k):\n",
    "\n",
    "\n",
    "    taken = closest(train,new,k)\n",
    "    def majority(taken_k):\n",
    "        ones = taken_k.where('TARGET_5Yrs', are.equal_to(1)).num_rows\n",
    "        zeros = taken_k.where('TARGET_5Yrs', are.equal_to(0)).num_rows\n",
    "        if ones > zeros:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return majority(taken)\n",
    "    \n",
    "classDetection(train_with_numeric,train_without_class.row(3),3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6007462686567164"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_with_numeric =test.drop('Name')\n",
    "\n",
    "\n",
    "def accuracy(train_data,test_data,k):\n",
    "    \n",
    "    test_features = test_data.drop('TARGET_5Yrs')\n",
    "    \n",
    "    def detection(row):\n",
    "        return classDetection(train_data,row,k)\n",
    "    \n",
    "    test_class_result = test_features.apply(detection)\n",
    "    return test_data.with_column('Target 5 year Class',test_class_result)\n",
    "\n",
    "table_with_predicted_class = accuracy(train_with_numeric,test_with_numeric,3)\n",
    "\n",
    "def accuracy_level(table):\n",
    "    number_row =table.num_rows\n",
    "    \n",
    "    target = table.column('TARGET_5Yrs')\n",
    "    target_classication=table.column('Target 5 year Class')\n",
    "    result = []\n",
    "    for i in range(0,len(target)):\n",
    "        if(target[i]==target_classication[i]):\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    np_result= np.array(result)  \n",
    "    count_true = np.count_nonzero(np_result==1)\n",
    "    \n",
    "    \n",
    "    return count_true/number_row\n",
    "    \n",
    "accuracy_level(table_with_predicted_class)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same model, try k = 1,2,3,4, and 5 and show which k value yields the best accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>K</th> <th>Accuracy</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>0.529851</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>0.55597 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3   </td> <td>0.600746</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4   </td> <td>0.600746</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5   </td> <td>0.649254</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "K    | Accuracy\n",
       "2    | 0.529851\n",
       "1    | 0.55597\n",
       "3    | 0.600746\n",
       "4    | 0.600746\n",
       "5    | 0.649254"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write your answer here**\n",
    "\n",
    "indek = np.arange(1,6)\n",
    "result=[]\n",
    "\n",
    "for i in indek:\n",
    "    table_with_predicted_class = accuracy(train_with_numeric,test_with_numeric,i)\n",
    "    result.append(accuracy_level(table_with_predicted_class))\n",
    "    \n",
    "result_table = Table().with_columns('K',indek,'Accuracy',result).sort('Accuracy')\n",
    "result_table\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We want to know which feautures are the most useful for this task. Set the value k to the value which gives the best performance in Question 3. Then for each feature you used previously, build a seperate knn model using the training data and all features except the corresponding feature, and calculate the performance on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Dropped Column</th> <th>Accuracy After Drop</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0             </td> <td>0.61194            </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1             </td> <td>0.671642           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2             </td> <td>0.664179           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3             </td> <td>0.645522           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4             </td> <td>0.652985           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5             </td> <td>0.630597           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6             </td> <td>0.649254           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7             </td> <td>0.652985           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8             </td> <td>0.660448           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>9             </td> <td>0.652985           </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (9 rows omitted)</p>"
      ],
      "text/plain": [
       "Dropped Column | Accuracy After Drop\n",
       "0              | 0.61194\n",
       "1              | 0.671642\n",
       "2              | 0.664179\n",
       "3              | 0.645522\n",
       "4              | 0.652985\n",
       "5              | 0.630597\n",
       "6              | 0.649254\n",
       "7              | 0.652985\n",
       "8              | 0.660448\n",
       "9              | 0.652985\n",
       "... (9 rows omitted)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_features= test_with_numeric.drop('TARGET_5Yrs')\n",
    "\n",
    "\n",
    "dropped_column_indeks=np.arange(0,test_features.num_columns)\n",
    "result=[]\n",
    "\n",
    "for i in range(0,test_features.num_columns):\n",
    "    table_with_predicted_class = accuracy(train_with_numeric.drop(i),test_with_numeric.drop(i),5)\n",
    "    result.append(accuracy_level(table_with_predicted_class))\n",
    "    \n",
    "result_table = Table().with_columns('Dropped Column',dropped_column_indeks,'Accuracy After Drop',result)\n",
    "result_table    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 11,  5, 13, 14,  3,  6, 10, 12, 16, 17, 18])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After drop some certain columns accuracy rate decrease, so these dropped column should be in the model\n",
    "\n",
    "worst_result_table = result_table.where('Accuracy After Drop',are.below(0.649254)).sort('Accuracy After Drop',descending=False)\n",
    "\n",
    "worst_result_table.column(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you have applied a leave-one-out method such that you exclude one feature and build the model with the rest. So if the performance of the model increases when we exclude a feature (compared to the model we use all features), that feature might not be a suitable feature for this task. So, exclude all features (if any) that yield higher performance when excluded than the model using all features. Then build the model with the remaining features. However, this time you will apply 5-fold cross validation. For cross-validation, do not shuffle the data. Report the accuracy for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Fold result0.5932835820895522\n",
      "2th Fold result0.6791044776119403\n",
      "3th Fold result0.6567164179104478\n",
      "4th Fold result0.6567164179104478\n",
      "5th Fold result0.6567164179104478\n",
      "K fold result 0.6485074626865672\n"
     ]
    }
   ],
   "source": [
    "data_dropped_columns = data.drop('Name').select( 0, 11,  5, 13, 14,  3,  6, 10, 12, 16, 17, 18,19)\n",
    "\n",
    "def kfold(data,k1,k2):\n",
    "    \n",
    "    index = np.arange(data.num_rows)\n",
    "    #shuffled_index = index.sample(with_replacement=False)\n",
    "    test_size = int(data.num_rows/k1)\n",
    "    total_accuracy = 0\n",
    "    \n",
    "    for i in np.arange(k1):\n",
    "        \n",
    "        test_index = index[i*test_size:(i+1)*test_size]\n",
    "        train_index = np.setdiff1d(index, test_index)\n",
    "        test = data.take(test_index)\n",
    "        train = data.take(train_index)\n",
    "        \n",
    "        \n",
    "        table_with_predicted_class = accuracy(train,test,5) \n",
    "        dogruluk_orani=accuracy_level(table_with_predicted_class)\n",
    "        total_accuracy=dogruluk_orani+total_accuracy\n",
    "        print(str(i+1)+'th Fold result'+str(dogruluk_orani))\n",
    "    return total_accuracy /k1\n",
    "\n",
    "print('K fold result '+str(kfold(data_dropped_columns,5,5))) \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
